{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Analysis - Portal da Transparência\n",
    "\n",
    "This notebook analyzes the quality of data from Portal da Transparência API.\n",
    "\n",
    "## Objectives:\n",
    "1. Assess data completeness\n",
    "2. Identify missing values and patterns\n",
    "3. Detect data anomalies\n",
    "4. Evaluate data consistency\n",
    "5. Generate data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path().absolute().parent.parent))\n",
    "\n",
    "from src.api.client import TransparenciaAPIClient\n",
    "\n",
    "# Initialize client\n",
    "client = TransparenciaAPIClient()\n",
    "print(\"API Client initialized successfully\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection for Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sample data from multiple endpoints\n",
    "data_samples = {}\n",
    "sample_size = 100  # Number of records to analyze per endpoint\n",
    "\n",
    "endpoints_to_analyze = [\n",
    "    (\"orgaos\", lambda: client.get_orgaos(sistema=\"siafi\", pagina=1, quantidade=sample_size)),\n",
    "    (\"contratos\", lambda: client.get_contratos(pagina=1, quantidade=sample_size)),\n",
    "    (\"fornecedores\", lambda: client.get_fornecedores(pagina=1, quantidade=sample_size)),\n",
    "    (\"licitacoes\", lambda: client.get_licitacoes(pagina=1, quantidade=sample_size)),\n",
    "    (\"pagamentos\", lambda: client.get_pagamentos(pagina=1, quantidade=sample_size))\n",
    "]\n",
    "\n",
    "print(\"Collecting data samples for quality analysis...\\n\")\n",
    "\n",
    "for name, fetch_func in endpoints_to_analyze:\n",
    "    try:\n",
    "        print(f\"Fetching {name}...\", end=\" \")\n",
    "        data = fetch_func()\n",
    "        if data:\n",
    "            data_samples[name] = pd.DataFrame(data)\n",
    "            print(f\"✓ Success ({len(data)} records)\")\n",
    "        else:\n",
    "            print(f\"⚠ No data returned\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {str(e)[:50]}...\")\n",
    "\n",
    "print(f\"\\nCollected data from {len(data_samples)} endpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Completeness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_completeness(df: pd.DataFrame, name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze data completeness for a DataFrame.\"\"\"\n",
    "    total_cells = df.size\n",
    "    missing_cells = df.isna().sum().sum()\n",
    "    \n",
    "    # Calculate completeness metrics\n",
    "    completeness = {\n",
    "        'endpoint': name,\n",
    "        'total_records': len(df),\n",
    "        'total_fields': len(df.columns),\n",
    "        'total_cells': total_cells,\n",
    "        'missing_cells': missing_cells,\n",
    "        'completeness_rate': (1 - missing_cells / total_cells) * 100 if total_cells > 0 else 0,\n",
    "        'missing_by_column': df.isna().sum().to_dict(),\n",
    "        'complete_records': len(df.dropna()),\n",
    "        'partial_records': len(df) - len(df.dropna())\n",
    "    }\n",
    "    \n",
    "    return completeness\n",
    "\n",
    "# Analyze completeness for all samples\n",
    "completeness_results = []\n",
    "\n",
    "for name, df in data_samples.items():\n",
    "    result = analyze_completeness(df, name)\n",
    "    completeness_results.append(result)\n",
    "    \n",
    "    print(f\"\\n{name.upper()} Completeness:\")\n",
    "    print(f\"  Total records: {result['total_records']}\")\n",
    "    print(f\"  Total fields: {result['total_fields']}\")\n",
    "    print(f\"  Completeness rate: {result['completeness_rate']:.2f}%\")\n",
    "    print(f\"  Complete records: {result['complete_records']}\")\n",
    "    print(f\"  Partial records: {result['partial_records']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize completeness rates\n",
    "completeness_df = pd.DataFrame([\n",
    "    {'Endpoint': r['endpoint'], 'Completeness Rate': r['completeness_rate']} \n",
    "    for r in completeness_results\n",
    "])\n",
    "\n",
    "fig = px.bar(\n",
    "    completeness_df,\n",
    "    x='Endpoint',\n",
    "    y='Completeness Rate',\n",
    "    title='Data Completeness by Endpoint',\n",
    "    text='Completeness Rate',\n",
    "    color='Completeness Rate',\n",
    "    color_continuous_scale='RdYlGn'\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
    "fig.update_layout(yaxis_title='Completeness Rate (%)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Value Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing value patterns for each endpoint\n",
    "for name, df in data_samples.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Missing Value Analysis: {name.upper()}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Calculate missing percentages\n",
    "    missing_pct = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "    missing_pct = missing_pct[missing_pct > 0]\n",
    "    \n",
    "    if len(missing_pct) > 0:\n",
    "        # Create visualization\n",
    "        fig = px.bar(\n",
    "            x=missing_pct.values,\n",
    "            y=missing_pct.index,\n",
    "            orientation='h',\n",
    "            title=f'Missing Values by Field - {name}',\n",
    "            labels={'x': 'Missing %', 'y': 'Field'},\n",
    "            text=missing_pct.values\n",
    "        )\n",
    "        \n",
    "        fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
    "        fig.update_layout(height=max(300, len(missing_pct) * 25))\n",
    "        fig.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nFields with missing values: {len(missing_pct)}\")\n",
    "        print(\"\\nTop fields with missing data:\")\n",
    "        for field, pct in missing_pct.head(5).items():\n",
    "            print(f\"  - {field}: {pct:.1f}% missing\")\n",
    "    else:\n",
    "        print(\"✓ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_types(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Analyze data types and potential issues.\"\"\"\n",
    "    type_analysis = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_data = df[col].dropna()\n",
    "        \n",
    "        if len(col_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        analysis = {\n",
    "            'column': col,\n",
    "            'dtype': str(df[col].dtype),\n",
    "            'unique_values': df[col].nunique(),\n",
    "            'null_count': df[col].isna().sum(),\n",
    "            'sample_values': list(col_data.head(3))\n",
    "        }\n",
    "        \n",
    "        # Check for potential date fields\n",
    "        if 'data' in col.lower() or 'date' in col.lower():\n",
    "            analysis['potential_date'] = True\n",
    "            \n",
    "        # Check for potential numeric fields stored as strings\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                # Test if values can be converted to numeric\n",
    "                pd.to_numeric(col_data.head(10), errors='coerce').notna().sum()\n",
    "                if pd.to_numeric(col_data.head(10), errors='coerce').notna().sum() > 5:\n",
    "                    analysis['potential_numeric'] = True\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        type_analysis.append(analysis)\n",
    "    \n",
    "    return pd.DataFrame(type_analysis)\n",
    "\n",
    "# Analyze data types for each endpoint\n",
    "for name, df in data_samples.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nData Type Analysis: {name.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    type_df = analyze_data_types(df, name)\n",
    "    \n",
    "    # Show potential issues\n",
    "    date_fields = type_df[type_df.get('potential_date', False) == True]['column'].tolist()\n",
    "    if date_fields:\n",
    "        print(f\"Potential date fields: {', '.join(date_fields)}\")\n",
    "        \n",
    "    numeric_fields = type_df[type_df.get('potential_numeric', False) == True]['column'].tolist()\n",
    "    if numeric_fields:\n",
    "        print(f\"Potential numeric fields stored as text: {', '.join(numeric_fields)}\")\n",
    "    \n",
    "    # Show data type distribution\n",
    "    dtype_counts = type_df['dtype'].value_counts()\n",
    "    print(\"\\nData type distribution:\")\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"  {dtype}: {count} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Value Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze value distributions for numeric columns\n",
    "for name, df in data_samples.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "        \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Also try to identify numeric columns stored as strings\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if 'valor' in col.lower() or 'value' in col.lower() or 'preco' in col.lower():\n",
    "            try:\n",
    "                df[f\"{col}_numeric\"] = pd.to_numeric(df[col], errors='coerce')\n",
    "                if df[f\"{col}_numeric\"].notna().sum() > len(df) * 0.5:\n",
    "                    numeric_cols.append(f\"{col}_numeric\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if numeric_cols:\n",
    "        print(f\"\\nNumeric Value Analysis: {name.upper()}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for col in numeric_cols[:5]:  # Analyze up to 5 numeric columns\n",
    "            col_data = df[col].dropna()\n",
    "            if len(col_data) > 0:\n",
    "                print(f\"\\n{col}:\")\n",
    "                print(f\"  Count: {len(col_data)}\")\n",
    "                print(f\"  Mean: {col_data.mean():.2f}\")\n",
    "                print(f\"  Median: {col_data.median():.2f}\")\n",
    "                print(f\"  Std Dev: {col_data.std():.2f}\")\n",
    "                print(f\"  Min: {col_data.min():.2f}\")\n",
    "                print(f\"  Max: {col_data.max():.2f}\")\n",
    "                \n",
    "                # Check for outliers using IQR method\n",
    "                Q1 = col_data.quantile(0.25)\n",
    "                Q3 = col_data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                outliers = ((col_data < (Q1 - 1.5 * IQR)) | (col_data > (Q3 + 1.5 * IQR))).sum()\n",
    "                print(f\"  Potential outliers: {outliers} ({outliers/len(col_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in each dataset\n",
    "duplicate_analysis = []\n",
    "\n",
    "for name, df in data_samples.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Check for complete duplicates\n",
    "    complete_dups = df.duplicated().sum()\n",
    "    \n",
    "    # Try to identify ID columns\n",
    "    id_columns = [col for col in df.columns if \n",
    "                  'id' in col.lower() or \n",
    "                  'codigo' in col.lower() or \n",
    "                  'numero' in col.lower()]\n",
    "    \n",
    "    subset_dups = 0\n",
    "    if id_columns:\n",
    "        # Check for duplicates on ID columns\n",
    "        subset_dups = df.duplicated(subset=id_columns[:1]).sum()\n",
    "    \n",
    "    analysis = {\n",
    "        'endpoint': name,\n",
    "        'total_records': len(df),\n",
    "        'complete_duplicates': complete_dups,\n",
    "        'id_columns': ', '.join(id_columns[:3]) if id_columns else 'None found',\n",
    "        'id_duplicates': subset_dups\n",
    "    }\n",
    "    \n",
    "    duplicate_analysis.append(analysis)\n",
    "\n",
    "# Display duplicate analysis\n",
    "dup_df = pd.DataFrame(duplicate_analysis)\n",
    "print(\"Duplicate Analysis Summary:\")\n",
    "print(dup_df.to_string(index=False))\n",
    "\n",
    "# Visualize if duplicates found\n",
    "if dup_df['complete_duplicates'].sum() > 0 or dup_df['id_duplicates'].sum() > 0:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        name='Complete Duplicates',\n",
    "        x=dup_df['endpoint'],\n",
    "        y=dup_df['complete_duplicates']\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        name='ID Duplicates',\n",
    "        x=dup_df['endpoint'],\n",
    "        y=dup_df['id_duplicates']\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Duplicate Records by Endpoint',\n",
    "        xaxis_title='Endpoint',\n",
    "        yaxis_title='Number of Duplicates',\n",
    "        barmode='group'\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Consistency Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform consistency checks\n",
    "consistency_issues = {}\n",
    "\n",
    "for name, df in data_samples.items():\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "        \n",
    "    issues = []\n",
    "    \n",
    "    # Check for date consistency\n",
    "    date_cols = [col for col in df.columns if 'data' in col.lower()]\n",
    "    for col in date_cols:\n",
    "        try:\n",
    "            # Try to parse dates\n",
    "            dates = pd.to_datetime(df[col], errors='coerce')\n",
    "            invalid_dates = dates.isna().sum() - df[col].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                issues.append(f\"Invalid date format in '{col}': {invalid_dates} records\")\n",
    "                \n",
    "            # Check for future dates\n",
    "            future_dates = (dates > pd.Timestamp.now()).sum()\n",
    "            if future_dates > 0:\n",
    "                issues.append(f\"Future dates found in '{col}': {future_dates} records\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Check for negative values in amount fields\n",
    "    amount_cols = [col for col in df.columns if \n",
    "                   'valor' in col.lower() or \n",
    "                   'preco' in col.lower() or\n",
    "                   'amount' in col.lower()]\n",
    "    \n",
    "    for col in amount_cols:\n",
    "        try:\n",
    "            values = pd.to_numeric(df[col], errors='coerce')\n",
    "            negative_values = (values < 0).sum()\n",
    "            if negative_values > 0:\n",
    "                issues.append(f\"Negative values in '{col}': {negative_values} records\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Check for unusually long strings\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in string_cols:\n",
    "        max_length = df[col].astype(str).str.len().max()\n",
    "        if max_length > 1000:\n",
    "            issues.append(f\"Very long strings in '{col}': max length {max_length}\")\n",
    "    \n",
    "    if issues:\n",
    "        consistency_issues[name] = issues\n",
    "\n",
    "# Display consistency issues\n",
    "if consistency_issues:\n",
    "    print(\"Data Consistency Issues Found:\")\n",
    "    print(\"=\" * 60)\n",
    "    for endpoint, issues in consistency_issues.items():\n",
    "        print(f\"\\n{endpoint.upper()}:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  ⚠ {issue}\")\n",
    "else:\n",
    "    print(\"✓ No major consistency issues found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive data quality report\n",
    "quality_report = {\n",
    "    \"report_metadata\": {\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"total_endpoints_analyzed\": len(data_samples),\n",
    "        \"sample_size_per_endpoint\": sample_size\n",
    "    },\n",
    "    \"summary\": {\n",
    "        \"average_completeness\": np.mean([r['completeness_rate'] for r in completeness_results]),\n",
    "        \"endpoints_with_duplicates\": sum(1 for d in duplicate_analysis if d['complete_duplicates'] > 0),\n",
    "        \"endpoints_with_issues\": len(consistency_issues)\n",
    "    },\n",
    "    \"detailed_analysis\": {}\n",
    "}\n",
    "\n",
    "# Add detailed analysis for each endpoint\n",
    "for name in data_samples.keys():\n",
    "    endpoint_report = {\n",
    "        \"completeness\": next((r for r in completeness_results if r['endpoint'] == name), None),\n",
    "        \"duplicates\": next((d for d in duplicate_analysis if d['endpoint'] == name), None),\n",
    "        \"consistency_issues\": consistency_issues.get(name, [])\n",
    "    }\n",
    "    quality_report[\"detailed_analysis\"][name] = endpoint_report\n",
    "\n",
    "# Save report\n",
    "reports_dir = Path().absolute().parent.parent / \"reports\"\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "report_filename = f\"data_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(reports_dir / report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(quality_report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nData quality report saved to: reports/{report_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Score Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visual scorecard\n",
    "scores = []\n",
    "\n",
    "for name in data_samples.keys():\n",
    "    # Calculate quality score (0-100)\n",
    "    completeness = next((r['completeness_rate'] for r in completeness_results if r['endpoint'] == name), 0)\n",
    "    has_duplicates = next((d['complete_duplicates'] > 0 for d in duplicate_analysis if d['endpoint'] == name), False)\n",
    "    has_issues = name in consistency_issues\n",
    "    \n",
    "    # Simple scoring: completeness - penalties\n",
    "    score = completeness\n",
    "    if has_duplicates:\n",
    "        score -= 10\n",
    "    if has_issues:\n",
    "        score -= 5 * len(consistency_issues.get(name, []))\n",
    "    \n",
    "    score = max(0, min(100, score))  # Ensure score is between 0-100\n",
    "    \n",
    "    scores.append({\n",
    "        'Endpoint': name,\n",
    "        'Quality Score': score,\n",
    "        'Grade': 'A' if score >= 90 else 'B' if score >= 80 else 'C' if score >= 70 else 'D' if score >= 60 else 'F'\n",
    "    })\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Create scorecard visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars\n",
    "colors = ['green' if s >= 80 else 'yellow' if s >= 60 else 'red' for s in scores_df['Quality Score']]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=scores_df['Endpoint'],\n",
    "    y=scores_df['Quality Score'],\n",
    "    text=[f\"{s:.1f}<br>Grade: {g}\" for s, g in zip(scores_df['Quality Score'], scores_df['Grade'])],\n",
    "    textposition='outside',\n",
    "    marker_color=colors\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Data Quality Scorecard',\n",
    "    xaxis_title='Endpoint',\n",
    "    yaxis_title='Quality Score',\n",
    "    yaxis_range=[0, 110],\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Add threshold lines\n",
    "fig.add_hline(y=90, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Excellent (A)\")\n",
    "fig.add_hline(y=80, line_dash=\"dash\", line_color=\"blue\", annotation_text=\"Good (B)\")\n",
    "fig.add_hline(y=70, line_dash=\"dash\", line_color=\"orange\", annotation_text=\"Fair (C)\")\n",
    "fig.add_hline(y=60, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Poor (D)\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nData Quality Summary:\")\n",
    "print(scores_df.to_string(index=False))\n",
    "print(f\"\\nAverage Quality Score: {scores_df['Quality Score'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations based on analysis\n",
    "print(\"DATA QUALITY RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. IMMEDIATE ACTIONS:\")\n",
    "\n",
    "# Check completeness\n",
    "low_completeness = [r['endpoint'] for r in completeness_results if r['completeness_rate'] < 80]\n",
    "if low_completeness:\n",
    "    print(f\"   - Investigate low completeness in: {', '.join(low_completeness)}\")\n",
    "    print(\"     Consider if missing values are expected or indicate data issues\")\n",
    "\n",
    "# Check duplicates\n",
    "has_duplicates = [d['endpoint'] for d in duplicate_analysis if d['complete_duplicates'] > 0]\n",
    "if has_duplicates:\n",
    "    print(f\"   - Remove duplicates from: {', '.join(has_duplicates)}\")\n",
    "    print(\"     Implement deduplication logic in data pipeline\")\n",
    "\n",
    "# Check consistency\n",
    "if consistency_issues:\n",
    "    print(f\"   - Fix consistency issues in: {', '.join(consistency_issues.keys())}\")\n",
    "    print(\"     Implement data validation rules\")\n",
    "\n",
    "print(\"\\n2. DATA PIPELINE IMPROVEMENTS:\")\n",
    "print(\"   - Implement data type validation during ingestion\")\n",
    "print(\"   - Add automated quality checks before storing data\")\n",
    "print(\"   - Create data quality monitoring dashboard\")\n",
    "print(\"   - Set up alerts for quality degradation\")\n",
    "\n",
    "print(\"\\n3. DATA GOVERNANCE:\")\n",
    "print(\"   - Document expected data formats and ranges\")\n",
    "print(\"   - Establish data quality SLAs with API provider\")\n",
    "print(\"   - Create data dictionary with business rules\")\n",
    "print(\"   - Implement regular quality audits\")\n",
    "\n",
    "print(\"\\n4. SPECIFIC FIELD RECOMMENDATIONS:\")\n",
    "# Identify fields that need attention\n",
    "for name, df in data_samples.items():\n",
    "    date_fields = [col for col in df.columns if 'data' in col.lower()]\n",
    "    if date_fields and df[date_fields].isna().sum().sum() > 0:\n",
    "        print(f\"   - {name}: Standardize date formats in {', '.join(date_fields)}\")\n",
    "\n",
    "print(\"\\n5. NEXT STEPS:\")\n",
    "print(\"   - Create automated data quality checks\")\n",
    "print(\"   - Build data cleaning pipelines\")\n",
    "print(\"   - Implement incremental data updates\")\n",
    "print(\"   - Design quality metrics tracking\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}